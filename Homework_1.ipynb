{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning - Homework 1 (due Sep. 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1: Legal reasoning (from Murphy 2.2).\n",
    "\n",
    "Suppose a crime has been committed. Blood is found at the scene for which there is no innocent explanation. It is of a type which is present in 1% of the population. The defendant is known to have this rare blood type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a. The prosecutor claims: “There is a 1% chance that the defendant would have the crime blood type if he were innocent. Thus there is a 99% chance that he guilty”. This is known as the prosecutor’s fallacy. What is wrong with this argument?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with this argument (the prosecutor's fallacy) comes from the problem of not understating conditional probability, and denying the use of the prior odds from which the defendant is guilty. The problem with this, is that we have no prior, no knowledge of what percentage can the defendant be guilty by itself, from this point, we only have the evidence of a blood type match between the crime scene and the defendant. If the blood test match is used to confirm the probility of the defedant being quilty, after it has been proven that the defendant has high probability of being quilty (like in example c below), then the blood test is solid evidence to prove the 'guiltiness' further. However, if the defendant was pulled from a database of blood matches at random from the city of the crime where \"the blood type would be found in approximately 8000 people\" like in example b, then randomness plays a big role, and then as any of the other 7999 in the city could be quilty too, the defender would have the advantage, as this prosecutor's claim, is not very effective (since the odds in this case would be not of being quilty, but of being selected at random from the database).\n",
    "\n",
    "The posterior probability could change depending of the prior, for example, if we use example b, where \"the crime ocurred in a city of 800,000 people and the blood type would be found in approximately 8000 people\", the prior would be small enough to change the posterior probability of the defentdant being quilty to be very small (even if we have a blood match), because this looks like a person taken at random from a large database. If we go for example c, where we are given \"the defendent was one of only 5 people with access to the crime scene\", this changes the prior so high, that with the blood test, as seen below, we get a very high probability of the defendant being quilty, close to 96.07%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The defender claims: “The crime occurred in a city of 800,000 people. The blood type would be found in approximately 8000 people. The evidence has provided a probability of just 1 in 8000 that the defendant is guilty, and thus has no relevance.” This is known as the defender’s fallacy. What is wrong with this argument (HINT: What happens to the prior in this case if there is other evidence presented)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with this argument is that is using a prior by itself, and yes, this prior is related to the posterior probability of the defendent is guilty. This argument would be correct if there are no other further evidence that points that the defendent being guilty. In this case, to get a complete picture, we would also need the likelihood of the sensitivity (true positive rate) and the false negative rate for the blood test match.\n",
    "\n",
    "However, if other evidence is presented, like in part c, where we find out that \"the defendent was one of only 5 people with access to the crime scene\", the prior gets overwritten from '1 in approximately 8000 people in the city with the same blood type at the crime scene or 0.000125' to just '1 in 5 people or 0.2'. Basically, the defender would have failed to take into account the prior probability of the defendant being quilty. That causes problems for the defendent, because not only this prior gets narrowed down; the defendant just mentioned that having that blood type is somewhat rare (1 in 8000 people or 0.000125), so the other 4 people in the room would most likely NOT have a blood match (very little probability) with the blood of the crime scene; which leaves the defendent very likely to be quilty, close to 96.07% as we found in c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe for both a and b, that the best statistician would produce both probabilities of the defendant being guilty and innocent, based on all the evidence, and compare them to each other to determine a final result to show to the judges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Suppose that forensic analysis tells us that that the blood test has 98% sensitivity (true positive rate) and a 1% false positive rate. Given the information presented in the above two questions, determine the posterior probability the the defendent is guilty, given that the defendent's blood type matches that found at the crime scene and that the defendent was one of only 5 people with access to the crime scene and that there is no other evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend: Let Q=Quilty: 1=True/Quilty, 0=False/Innocent; BT=Blood Test: 1=Match, 0=No Match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(Q=\\mathrm{1}|BT=\\mathrm{1}) = \\frac{P(BT=\\mathrm{1}|Q=\\mathrm{1}) * P(Q=\\mathrm{1})}{P(BT=\\mathrm{1}|Q=\\mathrm{1}) * P(Q=\\mathrm{1}) + P(BT=\\mathrm{1}|Q=\\mathrm{0}) * P(Q=\\mathrm{0})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = \\frac{(0.98) * (0.2)}{(0.98) * (0.2) + (0.01) * (0.8)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = 0.960784 = 96.07\\%$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2: Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One use of the naive Bayes classifier, which is still in practical use today, is as a spam filter.  Consider the corpus of text messages packaged with this homework, which are each labelled as either 'spam' or 'ham'.  In this case, naive Bayes utilizes a Bernoulli model that quantifies the probability of a given word given that the message is either spam or ham.  For example, investigating the text messages here, we find that the word *draw* shows up in spam 27 times, yet in ham only 5.  Thus, we have that\n",
    "$$ P(X=\\mathrm{draw}|Y=\\mathrm{ham}) = \\frac{5}{5+27}. $$\n",
    "\n",
    "While this is not particularly strong evidence on its own, we can create a powerful classifier by using the naive assumption in conjunction with all the words in a given message:\n",
    "$$ P(Y=\\mathrm{ham}|\\hat{X}) \\propto P(Y=\\mathrm{ham}) \\prod_{i=1}^n P(X=x_i|Y=\\mathrm{ham}), $$\n",
    "$$ P(Y=\\mathrm{spam}|\\hat{X}) \\propto P(Y=\\mathrm{spam}) \\prod_{i=1}^n P(X=x_i|Y=\\mathrm{spam}), $$\n",
    "where $x_i$ are the words in a given message. \n",
    "\n",
    "Your task is to write such a classifier.  I have taken the somewhat tedious step of parsing the data for you, yielding the variables *word_dictionary*, which contains the ham and spam counts for each word, as well as *training_labels*, which provides the spam/ham labels for each text message.  I have also parsed a set of test data: *test_messages* is a list, each entry containing another list of the words in the text message, as well as *test_labels* which contains the spam/ham label for each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Maps from 'ham' or 'spam' strings to zero or one\n",
    "def mapper(s):\n",
    "    if s=='spam':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Read in the text file\n",
    "f = open('SMSSpamCollection','r')\n",
    "lines = f.readlines()\n",
    "\n",
    "# Break out the test data\n",
    "test_lines = lines[:len(lines)//5]\n",
    "lines = lines[len(lines)//5:]\n",
    "\n",
    "# Instantiate the frequency dictionary and an array to\n",
    "# record whether the line is ham or spam\n",
    "word_dictionary = {}\n",
    "training_labels = np.zeros(len(lines),dtype=int)\n",
    "\n",
    "# Loop over all the training messages\n",
    "for i,l in enumerate(lines):\n",
    "    # Split into words\n",
    "    l = l.lower().split()\n",
    "    # Record the special first word which always ham or spam\n",
    "    if l[0]=='ham':\n",
    "        training_labels[i] = 1\n",
    "    # For each word in the message, record whether the message was ham or spam\n",
    "    for w in l[1:]:\n",
    "        # If we've never seen the word before, add a new dictionary entry\n",
    "        if w not in word_dictionary:\n",
    "            word_dictionary[w] = [1,1]\n",
    "        word_dictionary[w][mapper(l[0])] += 1\n",
    "        \n",
    "# Loop over the test messages\n",
    "test_labels = np.zeros(len(test_lines),dtype=int)\n",
    "test_messages = []\n",
    "for i,l in enumerate(test_lines):\n",
    "    l = l.lower().split()\n",
    "    if l[0]=='ham':\n",
    "        test_labels[i] = 1\n",
    "    test_messages.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I have provided code skeletons.  Your job is to make the code skeletons into an operational naive Bayes spam detector.  (you may discard these skeletons if you would prefer to code this from scratch).  Note that lines where you will need to change the code are marked with a '#!'.\n",
    "\n",
    "Your first task is train the model:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the prior P(Y=ham) ?\n",
    "ham_prior = len(test_labels[test_labels==1]) / len(test_labels)\n",
    "\n",
    "# What are the class probabilities P(X=word|Y=ham) for each word?\n",
    "ham_likelihood = {}\n",
    "for key,val in word_dictionary.items():\n",
    "    ham_likelihood[key] = val[1] / (val[0] + val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your next task is to make predictions on a set of test examples which were held back from the training procedure (see *test_messages* variable).  For each of these messages, compute the ham and spam probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to hold the ham and spam posteriors\n",
    "posteriors = np.zeros((len(test_lines),2))\n",
    "\n",
    "# Loop over all the messages in the test set\n",
    "for i,m in enumerate(test_messages):\n",
    "    posterior_ham = 1.0 * ham_prior\n",
    "    posterior_spam = 1.0 * (1 - ham_prior) #spam prior = 1 - ham_prior\n",
    "    #! Don't forget to include the prior!\n",
    "    # Loop over all the words in each message\n",
    "    for w in m:\n",
    "        # #! What is the purpose of this try/except handler?\n",
    "        # The purpose of this try/except handler is to just ignore cases where the key 'w' is not in the dictionary 'ham_likelihood'\n",
    "        try:\n",
    "            posterior_ham *= ham_likelihood[w]\n",
    "            posterior_spam *= (1-ham_likelihood[w]) \n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    # Notice the normalization factor (denominator) \n",
    "    # to turn these into proper probabilities!\n",
    "    posteriors[i,0] = posterior_spam/(posterior_spam + posterior_ham)\n",
    "    posteriors[i,1] = posterior_ham/(posterior_spam + posterior_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, make a ham/spam prediction based on your posterior probabilities.  Compare these to the labels contained in test_labels.  Report the accuracy of your classifier as percentage correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9389587073608617 = 93.89587073608617 %\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an array to record whether the prediction from the posteriors is ham or spam.\n",
    "# In this case, I am simplifying things by getting the bigger probability\n",
    "# round it to 0 or 1 accordingly, and compare the result to test_labels\n",
    "results = np.zeros(len(test_lines),dtype=int)\n",
    "\n",
    "for i,value in enumerate(results):\n",
    "    if (posteriors[i][0] > posteriors[i][1]):\n",
    "        prediction = 0\n",
    "    else:\n",
    "        prediction = 1\n",
    "    \n",
    "    if test_labels[i] == prediction:\n",
    "        results[i] = 1\n",
    "\n",
    "accuracy = len(results[results==1])/ len(results)\n",
    "percentage = accuracy * 100\n",
    "\n",
    "print(\"Accuracy: \", accuracy, \"=\", percentage, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
